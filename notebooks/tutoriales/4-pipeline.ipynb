{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A medida que hemos ido aprendiendo más y más funcionalidades de scikit, vemos que la cantidad de operaciones a realizar sobre nuestros datos aumenta. Por ejemplo, podemos tener que hacer varias operaciones de preprocessing, una feature selection, ajuste de los hiperparámetros del algoritmo y todo ello además, encerrado en un cross-validation. Para hacer todas estas operaciones de manera automática, scikit incorpora un módulo llamado `Pipeline`, que permite colocar diferencias operaciones que van a actuar de manera secuencial sobre los datos. \n",
    "\n",
    "Las ventajas de usar este módulo son:\n",
    "\n",
    "- **Convenciencia y encapsulacion**: Sólo hay que llamar una vez a `fit` y `predict` para que se realice sobre toda la secuencia de pasos\n",
    "- ** Selección de parámetros unificada**: Cada paso seguramente dependa de algún hiperparámetro que ajustar. Se pueden usar los metodos *grid search* para explorar dichos parámetros a la vez\n",
    "- **Seguridad**: Evita resultados demasiado optimistas al hacer algún paso antes de cross-validation. Una vez definido el pipeline, si lo metemos dentro de un esquema de cross-validation, **todos** los pasos se realizan sobre el training set. \n",
    "\n",
    "Todas las operaciones menos la última, transforman la data. Por tanto, todos los algoritmos que implementen estos pasos han de tener un método `fit` y otro `transform`. El último puede ser de cualquier tipo, aunque lo normal es que sea el clasificador que usamos para predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feat_sel = SelectKBest(k=1)\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline([\n",
    "    ('feat_sel', feat_sel), # Paso 1: hacer una feature selection usando ANOVA\n",
    "    ('normalizer', StandardScaler()), # Paso 2: Estandarizar los datos\n",
    "    ('clf', LogisticRegression()) # Paso 3- Clasificador\n",
    "])\n",
    "pipeline.steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(np.mean(cross_val_score(pip, X,y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'feat_sel__k': [1,2,3,4], 'clf__C': [0.01,0.1,1,10,100]}\n",
    "grid = GridSearchCV(pip, param_grid=param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos acceder a cada paso individual\n",
    "\n",
    "print(grid.best_estimator_.named_steps['feat_sel'].get_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos ver ahora cómo generaliza esto, lo podemos hacer haciéndo un holdout antes del grid search o metiéndolo dentro de un cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cross_val_score(grid, X,y, cv = 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencias: http://scikit-learn.org/stable/modules/pipeline.html#pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
